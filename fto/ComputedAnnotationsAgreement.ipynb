{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Customer Variables\n",
    "annotations_ousmane_200_json_path = \"inputs\\\\annotations-ousmane-200.json\" \n",
    "annotations_ousmane_200_csv_path = \"inputs\\\\annotations-ousmane-200.csv\"\n",
    "annotations_marco_1000_csv_path = \"inputs\\\\1000annotazioni.csv\"\n",
    "annotations_matched_200_csv_path = \"outputs\\\\annotations-matched-200.csv\"\n",
    "annotations_contains_matched_200_csv_path = \"outputs\\\\annotations_contains-matched-200.csv\"\n",
    "exact_agreement_columns = [\"author\", \"sent_id\", \"text\", \"TIME\", \"WRITER-AG\", \"EVENT\", \"ORG\", \"LOC\", \"ASP-EVENT\", \"STATE\", \"WRITER-PA\", \"REP-EVENT\"]\n",
    "soft_agreement_columns = [\"author\", \"sent_id\", \"text\", \"EVENT\", \"STATE\"]\n",
    "merge_by_columns = [\"author\", \"sent_id\", \"text\"]\n",
    "\n",
    "## Libraries Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform annotations file json to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function convert the annotation file json in a annotation file csv.\n",
    "def annotations_json_to_csv(path_file_json, annotator_name, path_file_csv) :\n",
    "    df = pd.DataFrame()\n",
    "    with open(path_file_json, \"r\", encoding='utf-8') as f:\n",
    "        file_contents = json.load(f)\n",
    "        for item in file_contents:\n",
    "            for annotation in item['annotations']:\n",
    "                container = dict()\n",
    "                container['annotator'] = annotator_name\n",
    "                container['author'] = item['data']['author']\n",
    "                container['sent_id'] = item['data']['sent_id']\n",
    "                container['text'] = item['data']['text']\n",
    "                for v in annotation['result']:\n",
    "                    container[v['value']['labels'][0]] = v['value']['text']\n",
    "                df = df.append(container, ignore_index=True)\n",
    "    df.to_csv(path_file_csv, index=False)\n",
    "\n",
    "# This function verify if string elements of two list are \"contains relations\".\n",
    "# \"contains relations\": for example we have two string str1 and str2, if str1 is sub strinf of str2\n",
    "# or str2 is sub string of str1\n",
    "def checkContainsRelations(items_1, items_2) :\n",
    "    computed = True\n",
    "    if len(items_1) != len(items_2) : return False\n",
    "    for index in range(len(items_1)) : \n",
    "        computed = computed and (str(items_1[index]) in str(items_2[index]) or str(items_2[index]) in str(items_1[index]))\n",
    "        if not computed : return False\n",
    "    return computed\n",
    "\n",
    "## This function merge two csv with Pandas\n",
    "def merged_two_csv(path_csv1, path_csv2, how_mode, onColumns) :\n",
    "    df1 = pd.read_csv(path_csv1)\n",
    "    df2 = pd.read_csv(path_csv2)\n",
    "    df = pd.merge(df1, df2, how=how_mode, on=onColumns) \n",
    "    return df\n",
    "\n",
    "def concateItems(item_1, item_2) :\n",
    "    item = \"Value1: \"\n",
    "    item += str(item_1) if str(item_1) != \"nan\" else \"MISSING_VALUE\"\n",
    "    item += \" & Value2: \"\n",
    "    item += str(item_2) if str(item_2) != \"nan\" else \"MISSING_VALUE\"\n",
    "    return item\n",
    "\n",
    "def swapedItems(item_1, item_2) :\n",
    "    temp = item_1\n",
    "    item_1 = item_2\n",
    "    item_2 = temp\n",
    "    return item_1,item_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trnasform Annotions file JSON to file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_json_to_csv(annotations_ousmane_200_json_path, \"ousmane\", annotations_ousmane_200_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute exact Agreement, outpu file => \"outputs\\\\annotations-matched-200.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exact_matched = merged_two_csv(annotations_ousmane_200_csv_path, annotations_marco_1000_csv_path, \"inner\", exact_agreement_columns)\n",
    "df_exact_matched.to_csv(annotations_matched_200_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Both df of annotatore and  make Pivot df\n",
    "df_ousmane = pd.read_csv(annotations_ousmane_200_csv_path)\n",
    "df_marco = pd.read_csv(annotations_marco_1000_csv_path)\n",
    "df_set_pivot = df_ousmane[[\"author\", \"sent_id\", \"text\"]].drop_duplicates(subset=[\"author\", \"sent_id\", \"text\"])\n",
    "\n",
    "# Create a matched Dictionnary container\n",
    "matched_container = {\n",
    "    'Author': [],\n",
    "    'SentenceId': [],\n",
    "    'EVENT': [],\n",
    "    'STATE': [],\n",
    "    'ASP-EVENT': [],\n",
    "    'REP-EVENT': [],\n",
    "    'MatchedInfo': [],\n",
    "    'Text': []\n",
    "}\n",
    "\n",
    "# Iterate Pivot df and Processing soft matching on Some columns \n",
    "for index, row in df_set_pivot.iterrows():\n",
    "    author = row[\"author\"]\n",
    "    sent_id = row[\"sent_id\"]\n",
    "    text = row[\"text\"]\n",
    "    df_x = df_ousmane.loc[(df_ousmane['author'] == author) & (df_ousmane['sent_id'] == sent_id) & (df_ousmane['text'] == text)]\n",
    "    df_y = df_marco.loc[(df_marco['author'] == author) & (df_marco['sent_id'] == sent_id) & (df_marco['text'] == text)]\n",
    "    if (df_x.shape[0] < df_y.shape[0]) :\n",
    "        df_x, df_y = swapedItems(df_x, df_y)\n",
    "    for index_x, row_x in df_x.iterrows() :\n",
    "        items_1 = [row_x[\"EVENT\"], row_x[\"STATE\"], row_x[\"ASP-EVENT\"], row_x[\"REP-EVENT\"]]\n",
    "        for index_y, row_y in df_y.iterrows() :\n",
    "            items_2 = [row_y[\"EVENT\"], row_y[\"STATE\"], row_y[\"ASP-EVENT\"], row_y[\"REP-EVENT\"]]\n",
    "            if items_1 == items_2 : \n",
    "                matched_container['Author'].append(author)\n",
    "                matched_container['SentenceId'].append(sent_id)\n",
    "                matched_container['Text'].append(text)\n",
    "                matched_container['EVENT'].append(row_x[\"EVENT\"])\n",
    "                matched_container['STATE'].append(row_x[\"STATE\"])\n",
    "                matched_container['ASP-EVENT'].append(row_x[\"ASP-EVENT\"])\n",
    "                matched_container['REP-EVENT'].append(row_x[\"REP-EVENT\"])\n",
    "                matched_container['MatchedInfo'].append(\"Exact Match\")\n",
    "                break\n",
    "            elif checkContainsRelations(items_1, items_2) :\n",
    "                matched_container['Author'].append(author)\n",
    "                matched_container['SentenceId'].append(sent_id)\n",
    "                matched_container['Text'].append(text)\n",
    "                if str(row_x[\"EVENT\"]) != \"nan\" or str(row_y[\"EVENT\"]) != \"nan\" : \n",
    "                    matched_container['EVENT'].append(concateItems(row_x[\"EVENT\"],row_y[\"EVENT\"]))\n",
    "                else : matched_container['EVENT'].append(\"\")\n",
    "                if str(row_x[\"STATE\"]) != \"nan\" or str(row_y[\"STATE\"]) != \"nan\" : \n",
    "                    matched_container['STATE'].append(concateItems(row_x[\"STATE\"], row_y[\"STATE\"]))\n",
    "                else : matched_container['STATE'].append(\"\")\n",
    "                if str(row_x[\"ASP-EVENT\"]) != \"nan\" or str(row_y[\"ASP-EVENT\"]) != \"nan\" : \n",
    "                    matched_container['ASP-EVENT'].append(concateItems(row_x[\"ASP-EVENT\"], row_y[\"ASP-EVENT\"]))\n",
    "                else : matched_container['ASP-EVENT'].append(\"\")\n",
    "                if str(row_x[\"REP-EVENT\"]) != \"nan\" or str(row_y[\"REP-EVENT\"]) != \"nan\" : \n",
    "                    matched_container['REP-EVENT'].append(concateItems(row_x[\"REP-EVENT\"], row_y[\"REP-EVENT\"]))\n",
    "                else : matched_container['REP-EVENT'].append(\"\")\n",
    "                matched_container['MatchedInfo'].append(\"Contains Relation Match\")\n",
    "                break\n",
    "\n",
    "# Convert the dictionary into DataFrame\n",
    "df_contains_matched = pd.DataFrame(matched_container, columns = ['SentenceId', 'EVENT', 'STATE', 'ASP-EVENT', 'REP-EVENT', 'MatchedInfo', 'Text'])\n",
    "df_contains_matched.replace(np.nan, '', regex=True)\n",
    "df_contains_matched.to_csv(annotations_contains_matched_200_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c0098ef03c01875785b14fb83d5161d4a7df326e3b00d12d4d2605823f1c481"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
